<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | dave^2 = -1]]></title>
  <link href="http://davesquared.net/categories/testing/atom.xml" rel="self"/>
  <link href="http://davesquared.net/"/>
  <updated>2022-10-15T16:55:10+11:00</updated>
  <id>http://davesquared.net/</id>
  <author>
    <name><![CDATA[David Tchepak]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Some mocking opinions]]></title>
    <link href="http://davesquared.net/2011/11/some-mocking-opinions.html"/>
    <updated>2011-11-22T22:25:00+11:00</updated>
    <id>http://davesquared.net/2011/11/some-mocking-opinions</id>
    <content type="html"><![CDATA[<p>I've been thinking through how I use test doubles (mocks, stubs, test spies, etc) recently, and thought I'd write down a snapshot of my current opinions on the subject.</p>




<h2>Don't mock types you don't own</h2>




<p>I've <a href="http://davesquared.net/2011/04/dont-mock-types-you-dont-own.html">written about this before</a>, and I still think it is good advice. Test down to your lowest level of abstraction, then integration / contract / acceptance test over the boundary. By mocking a type you don't own that dependency starts bleeding in to your code and pushing your own abstractions in potentially unhelpful ways. You're also not really testing much; unless you also have good contract tests then checking you've called a specific external method is not going to tell you much about whether your code does what it needs to.</p>




<p>Contrived example: say I was faking out <code>Math.Round()</code> (let's pretend it's an instance method or you are using a framework that can mock statics via the profiler API):</p>




<pre><code>[Test]
public void Calculate_with_rounding() {
    math.Round(2.5).Returns(3); //Fake math.Round
    var subject = new Calculation(math);

    Assert.AreEqual(subject.AddAndRound(1, 1.5), 3);
}
</code></pre>




<p>Perfectly reasonable? Well, except for the fact .NET uses banker's rounding and rounds <a href="http://stackoverflow.com/questions/977796/in-c-math-round2-5-result-is-2-instead-of-3-are-you-kidding-me">2.5 to 2</a> (and 1.5 to 2 for that matter). If you were using Python (which rounds away from 0), you would have been spot on. If you care about the rounding method, you've now got a bug.</p>




<p>If something as simple as rounding can trip us up, imagine what we could do if we start mocking ORM or ADO.NET calls.</p>




<h2>Try to avoid mocks in acceptance tests</h2>




<p>In my experience this tends to result in too much behaviour being pushed into the mocks. My first preference is to use real pieces, second is to hand-code fakes that have enough logic to work as required, and convenience methods to help tests configure them appropriately. As per &quot;don't mock types you don't own&quot;, it is also a good idea to test your fakes match the real behaviour.</p>




<h2>Learn mocking before a mocking framework</h2>




<p>I've often heard developers new to automated testing say things like &quot;I really need to learn (Rhino Mocks | Moq | Mocking Framework X)&quot;. I think this is the wrong emphasis; before learning a framework for creating test doubles it's important to understand how test doubles work and how to use them.</p>




<p>For me, a great way to learn was to hand-roll all my fake objects for my tests to act as required. Manually stubbing out values and/or recording calls gave me a good understanding of the different types of test doubles (mocks, spies, stubs etc.) and how they work. Once this got old (very quickly) it was fairly simple to take the behaviour I knew how to hand-code and translate that into the syntax required by a mocking framework. It just became a matter of automating what I was already doing. (It also helped me understand common difficulties like trying to mock non-virtual members.)</p>




<h2>Don't explictly test intermediate steps or inconsequential details</h2>




<p>If we assert on details of an implementation we tend to get tight coupling and brittle tests. An example I have seen fairly frequently is:</p>




<pre><code>[Test]
public void Should_get_the_widget_from_the_factory() {
    var factory = MockRepository.GenerateMock&lt;IWidgetFactory&gt;();
    var subject = new Foo(factory);
    subject.DoStuff();
    factory.AssertWasCalled(x =&gt; x.GetWidget());
}

[Test]
public void Should_turn_the_widget() {
    var widget = MockRepository.GenerateMock&lt;IWidget&gt;();
    var factory = MockRepository.GenerateStub&lt;IWidgetFactory&gt;();
    factory.Stub(x =&gt; x.GetWidget()).Return(widget);
    var subject = new Foo(factory);
    subject.DoStuff();
    widget.AssertWasCalled(x =&gt; x.Turn());
}
</code></pre>




<p>Here the first test is a completely redundant. The second test covers that entire code path (how else could the widget from the factory get turned, if the subject did not call the factory?). Now you could argue that you prefer the extra, explicit specification the first test provides, to which I'd respond that I don't think it's worth the pain from the additional friction it causes when you want to change this implementation detail. </p>




<p>Besides, what do we really care about for our subject? That it uses a factory? Or that it turns the widget? Focus on how you want the object to behave, not how it implements that behaviour.</p>




<p>This approach can help lead us to better abstractions, as we start identifying roles and responsibilities separately from implementation details. And it will definitely make your code easier to change without the friction of over-specified tests.</p>




<h2>Mock interaction with the contract, not the specific implementation</h2>




<p>On a highly related point, the aim of abstraction is decoupling from the implementation. If we are configuring our test doubles with lots of behaviour that our unit tests are relying on then our object is coupled to that particular implementation, not to a contract of behaviour or a role. For an abstraction to be effective we should be able to drop in a completely new implementation that fulfils the required role. This is not the case if we need to set up a test double's method to call another dependency and return some rearrangement of the result. If we're relying on that in our test then our abstraction has failed.</p>




<p>Sometimes you just get stuck with having to perform a callback from a stub, but in general if you are pushing behaviour into your mock, re-think the design or consider using a hand-coded fake before you go contorting your mocking framework.</p>




<h2>Beware over-abstraction</h2>




<p>It is quite easy to churn out layers of useless abstractions when using mock frameworks. Abstractions have a cost. Feedback from tests is great, but pay close attention to SOLID and the rules of simple design and call out to meaningful abstractions, rather than putting in a dependency just for testing. I wrote some <a href="http://davesquared.net/2011/06/abstraction-and-oo.html">guidelines on abstractions</a> a while back that I don't entirely disagree with yet.</p>




<h2>Some unanswered questions</h2>




<h3>Mocks vs. stubs, tell vs. ask.</h3>




<p>I've tended to prefer stubs over mocks (stubbing out the results of calls rather than checking they were received), as per the widget factory example above. This flies in the face of the &quot;Tell, don't ask&quot; principle, which recommends we don't ask a collaborator for some state and act on the result, but instead give the collaborator the state it needs from us and tell it what to do with it. This seems to suggest I should be using mocks (checking received calls) a whole lot more than I stub them out.</p>




<h3>Avoiding &quot;Yet Another Factory&quot;</h3>




<p>If an object news up something, our unit test will typically have almost no ability to affect that object. If we want to check our subject news up a view model and calls <code>Activate()</code> on it, we have no way of asserting this was done without exposing <code>IsActivated</code> and relying on that implementation detail. Leaky abstraction. Bad.</p>




<p>One solution is injecting a factory into our object. We can stub out what this returns, make it return another test double, and then check it received the <code>Activate()</code> call. Just introduce a factory. Yet another factory. Searching through files matching <code>*Factory</code> becomes an exercise akin to reading War and Peace. And they're generally not even <a href="http://en.wikipedia.org/wiki/Factory_pattern">real factories</a>! They don't choose a particular implementation, they are just a glorified wrapper over a single constructor.</p>




<p>Sure, I sometimes try to ease my conscience by injecting a factory method as a <code>Func&lt;T&gt;</code> which my IoC container helps me with. But deep down I know it's still YAF, and a small part of me dies.</p>




<p>I'm hoping choosing &quot;better&quot; abstractions will help me with this, but I've had limited success to date.</p>




<h3>Interface explosion</h3>




<p>C# seems to make it difficult to do testing without using interfaces. And so I end up pulling out yet another interface that will never see another implementation. I've heard <a href="https://twitter.com/shannoncornish">Shannon</a> refer to them as &quot;the new header files&quot;. Every class has its interface documented in its header/interface file. It's easy to say just choose better abstractions where the interface can be reused, but this is still something I struggle with.</p>




<h3>Mocking in dynamic languages</h3>




<p>This post has been written primarily from the perspective of static languages; I not sure how much (if any) applies to dynamic languages. From my limited experience testing and mocking seem to be done quite differently in languages like Ruby and Python. I'm keen to learn more about how mocking is done in these languages and see how much can help me improve how I test.</p>




<h2>End of transmission</h2>




<p>This has been a brain dump of my current opinions about mocking. If you agree, disagree, and/or can help me with some of my unanswered questions, please leave a comment.</p>




<p>Now if you'll excuse me, I'm off to code up yet another factory...</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Announcing NSubstitute]]></title>
    <link href="http://davesquared.net/2010/06/announcing-nsubstitute.html"/>
    <updated>2010-06-30T01:01:00+10:00</updated>
    <id>http://davesquared.net/2010/06/announcing-nsubstitute</id>
    <content type="html"><![CDATA[<p>Tonight at Sydney ALT.NET <a href="http://twitter.com/guywithbeard">Anthony Egerton</a> announced <a href="http://nsubstitute.github.com">NSubstitute</a>, his mocking framework for .NET 3.5+. I've been contributing some code to NSubstitute and I like to blog, so I thought I'd take it upon myself to do the written version of the announcement. :)</p>




<p>This all started a few months ago during some pair programming where we started discussing how we would ideally like our mocking code to read. Anthony came up with some neat syntax ideas and we decided to start working on it as a hobby project in our spare time, the aim being to play around with a simple, succinct syntax for mocking, as well as to try out some different testing techiques and to learn a bit about DynamicProxy.</p>


<p></p>

<p>We liked the syntax so much we've started using it on work projects, and so we thought we'd <a href="http://github.com/nsubstitute/NSubstitute">put it out there</a> in case anyone else was interested or has some ideas on how to improve it. It's still a little rough around the edges (the exception message formatting needs lots of work, and it doesn't support Mono or Silverlight yet), but it's pretty usable in its current state and should be enough to give people an idea of what we're aiming for.</p>




<h2>NSubstitute examples</h2>




<p>Say we have an <code>ICalculator</code> interface:</p>




<pre class="brush:csharp">
public interface ICalculator {
  int Add(int a, int b);
  string Mode { get; set; }
  event Action PoweringUp;
}
</pre>




<p>We can ask NSubstitute to create a substitute instance for this type. We could ask for a stub, mock, fake, spy, test double etc., but why bother when we just want to substitute an instance we have some control over?</p>




<pre class="brush:csharp">
var calculator = Substitute.For&lt;ICalculator&gt;();
</pre>




<p>
 Now we can tell our substitute to return a value for a call:
</p>




<pre class="brush:csharp">
calculator.Add(1, 2).Returns(3);
Assert.That(calculator.Add(1, 2), Is.EqualTo(3));
</pre>




<p>
We can check that our substitute received a call, and did not receive others:
</p>




<pre class="brush:csharp">
calculator.Add(1, 2);
calculator.Received().Add(1, 2);     
calculator.DidNotReceive().Add(5, 7);
</pre>




<p>If our <code>Received()</code> assertion fails, NSubstitute tries to give us some help as to what the problem might be:</p>




<pre>
NSubstitute.Exceptions.CallNotReceivedException : Expected to receive call:
    Add(1, 2)
Actually received:
    Add(4, 5)
    Add(3, 4)
</pre>




<p>We can also work with properties using the <code>Returns</code> syntax we use for methods, or just stick with plain old property setters (for read/write properties):</p>




<pre class="brush:csharp">
calculator.Mode.Returns("DEC");
Assert.That(calculator.Mode, Is.EqualTo("DEC"));

calculator.Mode = "HEX";
Assert.That(calculator.Mode, Is.EqualTo("HEX"));
</pre>




<p>NSubstitute supports argument matching for setting return values and asserting a call was received:</p>




<pre class="brush:csharp">
calculator.Add(10, -5);
calculator.Received().Add(10, Arg.Any&lt;int&gt;());
calculator.Received().Add(10, Arg.Is&lt;int&gt;(x =&gt; x &lt; 0));
</pre>




<p>We can use argument matching as well as passing a function to <code>Returns()</code> to get some more behaviour out of our substitute (possibly too much, but that's your call):</p>




<pre class="brush:csharp">
calculator
  .Add(Arg.Any&lt;int&gt;(), Arg.Any&lt;int&gt;())
  .Returns(x =&gt; (int)x[0] + (int)x[1]);
Assert.That(calculator.Add(5, 10), Is.EqualTo(15));
</pre>




<p><code>Returns()</code> can also be called with multiple arguments to set up a sequence of return values.</p>




<pre class="brush:csharp">
calculator.Mode.Returns("HEX", "DEC", "BIN");
Assert.That(calculator.Mode, Is.EqualTo("HEX")); 
Assert.That(calculator.Mode, Is.EqualTo("DEC")); 
Assert.That(calculator.Mode, Is.EqualTo("BIN")); 
</pre>




<p>Finally, we can raise events on our substitutes (unfortunately C# dramatically restricts the extent to which this syntax can be cleaned up):</p>




<pre class="brush:csharp">
bool eventWasRaised = false;
calculator.PoweringUp += () =&gt; eventWasRaised = true;

calculator.PoweringUp += Raise.Action();
Assert.That(eventWasRaised);
</pre>




<h2>How can I try this out?</h2>


<p>Easy, just head on over to <a href="http://nsubstitute.github.com">nsubstitute.github.com</a> and download the binary. Then add the <code>NSubstitute.dll</code> as a project reference, add <code>using NSubstitute;</code> to your CS file and start substituting. Or grab the source from the <a href="http://github.com/nsubstitute/NSubstitute">project site on GitHub</a> and start tinkering.</p>




<p>If you try it out I'd love to hear how you go!</p>




<h2>Some quick acknowledgements</h2>


<p>It doesn't seem right to plug this and not give kudos to some of the people that made it possible, both directly and indirectly.</p>




<p>First, <a href="http://twitter.com/guywithbeard">Anthony</a> deserves the credit for the awesome syntax ideas in NSub. I take full credit for all the implementation bugs, as well as for some of the ridiculous abstractions in the code (including a really dodgy, mini-IoC container for wiring up routes and handlers. Yuck. :)). <a href="http://troyhunt.com">Troy Hunt</a> did a great job of knocking out a logo for us. <a href="http://twitter.com/xerxesb">Xerxes</a> and <a href="http://twitter.com/shannoncornish">Shannon</a> also helped out with some code and suggestions respectively. <a href="http://kozmic.pl/">Krzysztof</a> also provided some much needed help over email and twitter on how to dynamically create delegates using .NET 3.5 expressions.</p>




<p>There are also a few people and projects that NSubstitute owes its existence to. <a href="http://ayende.com">Ayende</a> and the awesome <a href="http://ayende.com/projects/rhino-mocks.aspx">Rhino Mocks</a> project really started us mocking in the first place, and did a great job making mocking viable on the .NET platform. Also thanks to <a href="http://www.clariusconsulting.net/blogs/kzu/">Daniel Cazzulino</a> and <a href="http://code.google.com/p/moq/">moq</a> for bringing Arrange Act Assert-style mocking  to .NET (to the world?). NSubstitute relies entirely on <a href="http://davesquared.net/2008/10/very-basics-of-aaa-with-rhino-mocks-35.html">AAA mocking</a> for its syntax, intentionally providing no support for strict mocks or record/replay. And finally to <a href="http://www.castleproject.org/">Castle Project's DynamicProxy</a> which we rely on (like almost everyone else) to generate our proxies.</p>




<p>&nbsp;</p>


<p>Happy substituting! :)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TDD, not UTDD]]></title>
    <link href="http://davesquared.net/2010/06/tdd-not-utdd.html"/>
    <updated>2010-06-04T23:16:00+10:00</updated>
    <id>http://davesquared.net/2010/06/tdd-not-utdd</id>
    <content type="html"><![CDATA[<p>When I first learned TDD I was taught that the first step in the process is to write a failing <i>test</i>, not specifically a failing <i>unit test</i>. After all, it is Test Driven Development, not Unit Test Driven Development. I even read books that were apparently written using a TDD-style approach, without a unit test in sight*. This didn't stop me from focussing almost entirely on using unit tests for TDD.</p>




<p>Fast forward a few years and I'm now finding a lots of benefits in other forms of testing for TDD, to complement the <a href="http://www.artima.com/weblogs/viewpost.jsp?thread=126923">traditional unit test</a>.</p>




<div style="font-size: x-small; font-style: italic;"><b>*</b> In case you're wondering how this works:  write the goal for an unwritten section, write the section, verify it meets the goal, edit. Red, green, refactor. :)</div>




<h2>Accepting acceptance tests</h2>




<p>Acceptance testing is a practice that seems very easy to get wrong in ways that cause a lot of friction, resulting in it being ignored or given only cursory treatment by developers. This is unfortunate, as I see acceptance testing as essential for effective TDD.</p>




<p>In Steve Freeman's and Nat Pryce's <a href="http://www.amazon.com/Growing-Object-Oriented-Software-Guided-Tests/dp/0321503627">Growing Object Oriented Software, Guided by Tests</a>, the first failing test they write is an acceptance test for the feature they are working on. They then drill down into unit tests so they can take small steps to incrementally build an implementation that passes the acceptance criteria. This was how I was initially introduced to TDD from reading about Extreme Programming (XP): an outer TDD cycle with acceptance tests, and an inner cycle with unit tests that had several iterations to get the acceptance test to pass.</p>




<p>The key to effective acceptance tests (at least for me, YMMV) is making sure they exercise a specific feature of the system from top to bottom, using as much of the real system as possible. It should clearly specify the behaviour of that feature -- once it passes you should be fairly confident that the customer's requirements for that feature have been met.</p>




<p>The main benefit I've found from acceptance testing is that the feedback from these tests help produce an architecture that is flexible, maintainable, and scriptable by virtue of being testable at such a high level. They also help me focus on exactly what I need to get this feature done, which in turn helps guide where I should start applying unit tests to drive the more specific elements of my design.</p>


<p></p>

<p>These benefits, using tests to define and design, are fairly universal to TDD regardless of which type of tests are used. In the case of acceptance tests, the large scope of the tests provide feedback on the larger aspects of the design.</p>




<p>I've also found acceptance tests to be invaluable when I've had to make radical design changes (e.g. when I've stuffed up somewhere), letting me cull over-specified unit tests and make sweeping changes while still having enough coverage to be confident the software works.</p>




<p>If you're doing TDD but not using acceptance tests, or have tried acceptance testing before but haven't been able to make it work for you, I'd really recommend giving it another shot. Don't worry about them being customer-writable (or even customer-readable for now, provided you can explain what is being tested), don't worry about what tool you use, just get them working. You're architecture will thank you for it. :)</p>


<p></p>

<h2>Don't mock types you don't own -- integration test them!</h2>




<p>Recently I was test driving some code that uses Castle DynamicProxy. I mocked out the Castle interface and checked my subject under test interacted with that library in a way that I thought was correct. The problem here is I do not own the Castle type, and <a href="http://stevef.truemesh.com/archives/000194.html">you should not mock types you don't own</a>.</p>




<p>Mocking types you don't own gives you very little in the way of ensuring correctness, and is potentially misleading in terms of the design guidance it provides. The problem is that you are testing based on your assumption of how the type works, not how it actually works. Sure, you're testing that your code correctly calls the method you told it to, but what about testing it calls the correct method? If the type changes in a later version, or if it's behaviour is slightly different than you expect under different conditions or arguments, then your tests can pass but your software fails. A misleading test like this can be more harmful than having no test.</p>




<div class="note"><b>Aside:</b> The same criticism can be levelled at mocking in general. The difference is that you have tests defining how your own types work, and have the ability to easily change the types if they do not function as required.</div>




<p>Another drawback, especially if you are working with libraries or frameworks that are not designed in a particularly test-friendly way (to put it diplomatically**), is that you may end up starting to push the behaviour of those libraries into those mocks in order for your class under test to interact with them in a meaningful way. Once you start simulating behaviour in your mocks you are doing it wrong -- you are well on your way to brittle, over-specified, complicated tests.</p>




<div style="font-size: x-small; font-style: italic"><b>**</b>  I'm not talking about Castle here, it's awesome. I will remind readers I have worked with SharePoint before... :)</div>




<p>Of course, if you are avoiding mocking types you don't own, this implies you need to use the real types, which means we are in the realms of integration testing. For my Castle-calling code, I ended up unit testing down to my own class that needed to use Castle to achieve something, then writing integration tests with real Castle objects to ensure that my class actually did use Castle correctly. This ended up being much more valuable to me, and much more flexible. It was more valuable because my tests actually told me my class was using the library correctly and was getting the results my system required, rather than just calling the method I thought was needed. It was more flexible because I had not over-specified every interaction with the third-party library, and so could easily and independently vary both my code and how my code interacted with that library.</p>




<p>I've had a habit of avoiding integration tests as I always assumed they had too wider scope and were too slow to be useful. Now I look forward to hitting a case I can easily cover with integration tests, as it means I've reached the bottom of my software's abstractions and can just test a concrete piece that actually does some real work by interacting with its environment.</p>




<div class="note"><b>Note:</b> A few words of caution about integration tests. I wouldn't recommend switching to integration tests until you are at the very bottom layers of abstraction. Test-drive down until you reach a single class that is an effective facade for some behaviour from a third-party library, then use integration tests to make sure it works as required. Integration tests can also slow down your test suite if they end up hitting the file system, database etc., in which case you should make sure you are able to run them separately from your unit tests and only run them when needed (such as prior to checkin or when you change something related).</div>




<h2>Conclusion</h2>




<p>I still rely very heavily on unit tests when test driving software, but I feel it is really important to know when to use other forms of testing with TDD (and without TDD for that matter). Acceptance tests are a great way to kick off a TDD cycle from the top down, while integration tests are invaluable once you reach the bottom and need to write the code that interacts with the rest of the world. Then there's unit testing for everything in between.</p>




<p>Finally, of course, there's manual, exploratory testing. This probably won't feature too much in your standard TDD cycle, but is so important for checking your software actually works that it didn't feel right not to mention it. :)</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mocking delegates with Rhino Mocks]]></title>
    <link href="http://davesquared.net/2009/12/mocking-delegates-with-rhino-mocks.html"/>
    <updated>2009-12-16T13:58:00+11:00</updated>
    <id>http://davesquared.net/2009/12/mocking-delegates-with-rhino-mocks</id>
    <content type="html"><![CDATA[<p>I recently found out that Rhino Mocks can mock delegates. Not that I didn't think it couldn't, it just never occurred to me to try. But it turns out to be quite nice for stubbing delegate calls or for checking they were called. Say we have the following class:</p>




<pre class="brush:csharp">
public class SomeClass {
    private readonly Func&lt;int, int&gt; _mapper;

    public SomeClass(Func&lt;int, int&gt; mapper) {
        _mapper = mapper;
    }

    public int DoSomething(int toThisInt) {
        return _mapper(toThisInt);
    }
}
</pre>




<p>Here's an example of testing that a simple <code>Func&lt;int, int&gt;</code> delegate is called correctly by our class under test without using Rhino Mocks:</p>




<pre class="brush:csharp">
[Test]
public void ManualFakeDelegate() {
    //Arrange
    var wasCalled = false;
    var intMapped = 0;
    var expectedResult = 1234;
    Func&lt;int, int&gt; fakeMapper = i =&gt; {
                        wasCalled = true;
                        intMapped = i;
                        return expectedResult;
                    };
    var someClass = new SomeClass(fakeMapper);

    //Act
    var result = someClass.DoSomething(10);

    //Assert
    Assert.True(wasCalled);
    Assert.AreEqual(intMapped, 10);
    Assert.AreEqual(expectedResult, result);
}
</pre>




<p>Now using Rhino Mocks:</p>




<pre class="brush:csharp">
[Test]
public void MockingDelegates() {
    var stubMapper = MockRepository.GenerateStub&lt;Func&lt;int, int&gt;&gt;();
    var expectedResult = 1234;
    stubMapper.Stub(x =&gt; x(10)).Return(expectedResult);            
    var someClass = new SomeClass(stubMapper);

    var result = someClass.DoSomething(10);

    Assert.AreEqual(expectedResult, result);
}
</pre>




<p>We no longer have to maintain all that test state to assert against, nor do we need to create any fake delegate implementation. We can also use <code>stubMapper.AssertWasCalled(x =&gt; x(10))</code>, but in this case that is already tested implicitly through the stubbed call and assertion.</p>




<p>In the first case, we could move some more advanced logic into our <code>fakeMapper</code> to do more advanced parameter checking and avoid some of the extra state and assertions, but that is potentially error-prone and we get it for free with our mocking library.</p>




<p>As an aside, you can obviously also mock <code>Action</code> or <code>Func</code>, but the <code>wasCalled</code>/<code>fakeMapper</code> approach is probably easier in that case.</p>




<p>Not something I'll need very often, but nice to know for those rare occasions were I do.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coding tiger, hidden responsibility]]></title>
    <link href="http://davesquared.net/2009/08/coding-tiger-hidden-responsibility.html"/>
    <updated>2009-08-21T22:03:00+10:00</updated>
    <id>http://davesquared.net/2009/08/coding-tiger-hidden-responsibility</id>
    <content type="html"><![CDATA[<p>During a recent pursuit of the Single Responsibility Principle, I stumbled upon an interesting place a responsibility can hide. Here's our task: we want to write a <code>PersistenceService</code> class that will let us save some <code>Results</code> to a file. These results will be stored as a serialised array of integers (<code>int[]</code>).</p>




<p>I'm going to use a bit of an unusual approach for writing the array out to the file. Commonly we'd have a serialiser class that would open up a file (or ask a dependency to open up the file), write the serialised data, then close and dispose the file. Instead we'll invert control a little. We'll pass in an existing file stream, and the serialiser class will write to it. The type and lifetime of the stream will be managed as an entirely separate responsibility.</p>




<h2>Coding tiger</h2>




<pre class="brush:csharp">
public class PersistenceService {
    private IFileStreamer _fileStream;
    private IIntegerArrayDataSerialiser _serialiser;

    public PersistenceService(IFileStreamer fileStream, IIntegerArrayDataSerialiser serialiser) {
        _fileStream = fileStream;
        _serialiser = serialiser;
    }

    public void SaveResults(Results results, string filePath) {
        _fileStream.Write(filePath, stream =&gt; _serialiser.Serialise(results.GetFoos(), stream));
    }
}
</pre>




<p>Here you'll see we are using an <code>IFileStreamer</code> to manage the lifetime of the stream, and using <code>IIntegerArrayDataSerialiser</code> to manage the serialisation. Our <code>PersistenceService</code> class itself just coordinates those dependencies, which should be its single responsibility. Let's run through the two collaborators before we move on, just so we have a working code sample.</p>




<pre class="brush:csharp">
public interface IIntegerArrayDataSerialiser {
    void Serialise(int[] data, Stream stream);
}

public class IntegerArrayDataSerialiser : IIntegerArrayDataSerialiser {
    private IFormatter formatter;

    public IntegerArrayDataSerialiser(IFormatter formatter) {
        this.formatter = formatter;
    }

    public void Serialise(int[] data, Stream stream) {
        formatter.Serialize(stream, data);
    }
}
</pre>




<p>We'll create our <code>IntegerArrayDataDeserialiser</code> with a <code>BinaryFormatter</code> (an <code>IFormatter</code> from <code>System.Runtime.Serialization.Formatters.Binary</code> in the framework), and we are basically just wrapping this class. Finally, we have our <code>FileStreamer</code>:</p>




<pre class="brush:csharp">
public interface IFileStreamer {
    void Write(string path, Action&lt;Stream&gt; streamProcessor);
}

public class FileStreamer : IFileStreamer {
    public void Write(string path, Action&lt;Stream&gt; streamProcessor) {
        using (var stream = File.OpenWrite(path)) {
            streamProcessor(stream);
        }
    }
}
</pre>




<p>The <code>FileStreamer</code> has the single responsibility of managing the lifetime of the stream used to write the file. It is basically a creational responsibility. And, believe it or not, this all works just fine.</p>




<p>So, have you spotted the hidden responsibility? It's in the <code>PersistenceService</code>. If you have, then nice work! I didn't spot it at all, although <a href="http://twitter.com/guywithbeard">a colleague</a> was able to point it out to me later. What I did spot though was a sign of potential trouble, not from the code, but from the tests...</p>




<h2>Testing times</h2>




<p>How would you test the <code>PersistenceService</code> as implemented? Despite the simplicity of the implementation, it is quite messy. If you haven't noticed the responsibility have a go at writing a test and see what gives you trouble. Here was how I finally got the test to pass:</p>




<pre class="brush:csharp">
public class PersistenceServiceFixture {
  [TestFixture]
  public class When_saving_data {
    private PersistenceService sut;
    private FakeFileStreamer fileStreamer;
    private FakeSerialiser serialiser;
    private int[] data;
    private Stream stream;
    private string path;

    [Test]
    public void Should_write_serialised_results_to_file_stream_from_given_file_path() {
        Assert.That(fileStreamer.PathUsed, Is.EqualTo(path));
        Assert.That(serialiser.DataSerialised, Is.SameAs(data));
        Assert.That(serialiser.StreamUsedToSerialise, Is.SameAs(stream));
    }

    [SetUp]
    public void Context() {
        stream = new MemoryStream();
        fileStreamer = new FakeFileStreamer(stream);
        serialiser = new FakeSerialiser();
        data = new[] {1, 2, 3, 4, 5};
        path = &quot;some path&quot;;

        sut = new PersistenceService(fileStreamer, serialiser);
        sut.SaveResults(new Results(data), path);
    }

    class FakeFileStreamer : IFileStreamer {
        private Stream stream;
        public string PathUsed;

        public FakeFileStreamer(Stream stream) {
            this.stream = stream;
        }

        public void Write(string path, Action&lt;Stream&gt; streamProcessor) {
            PathUsed = path;
            streamProcessor(stream);
        }
    }

    class FakeSerialiser : IIntegerArrayDataSerialiser {
        public Stream StreamUsedToSerialise;
        public int[] DataSerialised;
        public void Serialise(int[] data, Stream stream) {
            DataSerialised = data;
            StreamUsedToSerialise = stream;
        }
    }
  }
}
</pre>




<p>I had to manually fake out both dependencies. I needed to put some behaviour in my <code>FakeFileStreamer</code> so that it would call our <code>Action&lt;Stream&gt;</code> function that the <code>PersistenceService</code> passes to it from the <code>IIntegerDataSerialiser</code>. By exposing the arguments used to call our <code>FakeFileStreamer</code> and <code>FakeSerialiser</code> we could then assert on them within our test. Not exactly pretty, is it?</p>




<p>What we'd like to do is to use our trusty mocking framework to generate an <code>IFileStreamer</code> and <code>IIntegerArrayDataSerialiser</code>, stub out a value and assert that the stream was written to.</p>




<p>Unfortunately we can't do that, because of a lurking menace...</p>




<h2>Hidden responsibility</h2>




<p>Let's take a closer look at the <code>PersistenceService.SaveResults()</code> method:</p>




<pre class="brush:csharp">
    public void SaveResults(Results results, string filePath) {
        _fileStream.Write(filePath, stream =&gt; _serialiser.Serialise(results.GetFoos(), stream));
    }
</pre>




<p>This is simply coordinating the class' two dependencies, right? It calls the <code>Write()</code> method of our <code>IFileStreamer</code>, and passes in the <code>Serialise()</code> method of our <code>IIntegerArrayDataSerialiser</code>. That coordination is one responsibility. So what is making this so annoying to test? My <a href="http://twitter.com/guywithbeard">bearded colleague</a> was able to walk me through the following steps to reveal (and subsequently fix) the problem. (This post is my translation of his explanation. His explanation was great, any mistakes made in this account are mine. :))</p>




<p>Well, firstly, we'd really like to be able to assert something like this in our test:</p>




<pre class="brush:csharp">
fileStreamer.AssertWasCalled(x => x.Write(path, stream =&gt; serialiser.Serialise(results.GetFoos(), stream));
</pre>




<p>That way we could be sure that our <code>PersistenceService</code> was producing the expected call to our <code>fileStreamer</code>, passing in the correct pointer to our <code>serialiser.Serialise()</code> method. So what's stopping us? Well the <code>AssertWasCalled()</code> method on Rhino Mocks will check the arguments for the call. It will get the path right, but we are creating a new <code>Action&lt;Stream&gt;</code> delegate to pass in our serialisation function, so we can't compare it to the one used by the <code>PersistenceService</code>.</p>




<p>Did you notice that? I didn't, despite hours of looking :). We are <b>creating</b> a new delegate. If we had that delegate instance we could compare the arguments in our test. But we don't, because of this line in <code>PersistenceService</code>:</p>




<pre class="brush:csharp">
    public void SaveResults(Results results, string filePath) {
        _fileStream.Write(filePath, stream =&gt; _serialiser.Serialise(results.GetFoos(), stream));
    }
</pre>




<p>That simple <code>stream =&gt; _serialiser.Serialise(...)</code>  lambda declaration is creating a delegate instance. So now <code>PersistenceService</code> isn't just <i>coordinating</i> dependencies, but it is <i>creating</i> a new object! That's two responsibilities! We are violating SRP, and that's what our test is telling us.</p>




<h2>Resassigning responsibilities</h2>




<p>My <a href="http://twitter.com/guywithbeard">bearded colleague</a> suggested we move the responsibility for creating this serialisation delegate. Instead of the <code>PersistenceService</code> creating it from our <code>IIntegerArrayDataSerialiser</code>, he reasoned, why not just get the <code>IIntegerArrayDataSerialiser</code> to create it for us? After all, serialisation is its job, and for serialisation our current design needs an <code>Action&lt;Stream&gt;</code>. (Although it is not really an <code>IIntegerArrayDataSerialiser</code> any more, we should probably rename it to a <code>IIntegerArraySerialisationFactory</code> or something. We'll keep it as is just to keep things simple -- its hard enough to follow code samples on a blog without following renames too.)</p>


<p></p>

<pre class="brush:csharp">
public interface IIntegerArrayDataSerialiser {
    Action&lt;Stream&gt; GetStreamSerialiser(int[] data);
}

public class IntegerArrayDataSerialiser : IIntegerArrayDataSerialiser {
    private IFormatter formatter;
    public IntegerArrayDataSerialiser(IFormatter formatter) {
        this.formatter = formatter;
    }

    public Action&lt;Stream&gt; GetStreamSerialiser(int[] data) {
        return stream =&gt; formatter.Serialize(stream, data);
    }
}
</pre>




<p>Notice this class' responsibility is clearer now. Before it was pretty much just a wrapper around <code>IFormatter</code>. Now its responsibility is creational: it is creating a delegate for serialisation from its <code>IFormatter</code>. Let's see how this affects the rest of the code. Our <code>FileStreamer</code> can remain unchanged, so now we just need to update our <code>PersistenceService</code> to call the new factory method on our <code>IIntegerDataArraySerialiser</code>.</p>




<pre class="brush:csharp">
public class PersistenceService {
    /* ... snip ... */
    public void SaveResults(Results results, string filePath) {
        _fileStream.Write(filePath, _serialiser.GetStreamSerialiser(results.GetFoos()));
    }
}
</pre>




<p>Now let's see if this makes everything easier to test.</p>




<pre class="brush:csharp">
[TestFixture]
public class When_saving_data {
    private PersistenceService sut;
    private IFileStreamer fileStreamer;
    private IIntegerArrayDataSerialiser serialiser;
    private int[] data;
    private string path;
    private Action&lt;Stream&gt; streamProcessor;

    [Test]
    public void Should_write_serialised_results_to_file_stream_from_given_file_path() {
        fileStreamer.AssertWasCalled(x =&gt; x.Write(path, streamProcessor));
    }

    [SetUp]
    public void Context() {
        streamProcessor = stream =&gt; { };
        data = new[] { 1, 2, 3, 4, 5 };
        path = &quot;some path&quot;; 
        fileStreamer = MockRepository.GenerateStub&lt;IFileStreamer&gt;();
        serialiser = MockRepository.GenerateStub&lt;IIntegerArrayDataSerialiser&gt;();
        serialiser.Stub(x =&gt; x.GetStreamSerialiser(data)).Return(streamProcessor);

        sut = new PersistenceService(fileStreamer, serialiser);
        sut.SaveResults(new Results(data), path);
    }
}
</pre>




<p>A bit simpler, no? We can now get rid of our hand-coded test doubles and the logic they contained. And now we have access to the <code>Action&lt;Stream&gt;</code> delegate instance that was giving us trouble before. As a result, our assertion (<code>fileStreamer.AssertWasCalled(...)</code>) is very straight forward and is checking that our <code>PersistenceService</code> did exactly what it was meant to. </p>




<p>Now this was mainly done as a coding exercise, so I'm not advocating this design at all, but I do find the realisation that an anonymous delegate or lambda is actually a creational responsibility really useful. It's definitely going to help me divide up responsibilities better in future.</p>

]]></content>
  </entry>
  
</feed>
