<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: imho | dave^2 = -1]]></title>
  <link href="http://davesquared.net/categories/imho/atom.xml" rel="self"/>
  <link href="http://davesquared.net/"/>
  <updated>2022-10-15T16:55:10+11:00</updated>
  <id>http://davesquared.net/</id>
  <author>
    <name><![CDATA[David Tchepak]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reasoning and mutability]]></title>
    <link href="http://davesquared.net/2013/03/reasoning-and-mutability.html"/>
    <updated>2013-03-11T23:49:00+11:00</updated>
    <id>http://davesquared.net/2013/03/reasoning-and-mutability</id>
    <content type="html"><![CDATA[<p>One thing I often hear about functional programming is that its requirement for immutability makes programs easier to reason about. To me this seems intuitively true -- it's got to be easier to work out what a program does without having to keep track of changing state while evaluating programs, right?</p>

<p>I wanted to challenge my assumptions about this. Could I convince myself that one is unambiguously easier to reason about? And if so, what is it about the other that makes it more difficult to reason about?</p>

<p>To do this I tried tracing through some examples of mutable and immutable data structures. I tried to use similar, "object" styles for both, so that the characteristic difference between them was the mutability of their internal data (rather than getting thrown off by differences between functional and OO styles).</p>

<p>I'd love to get your thoughts for and against these ideas. I am especially likely to be the victim of confirmation bias on this one, so I'm counting on you to keep me honest. Leave comments or send me email please! :)</p>

<!-- more -->


<h2>Counter example</h2>

<p>Let's start by looking at a simple example of a counter that has an <code>inc()</code> method to increment the counter, and a <code>value()</code> method to return its value. One counter will be a mutable data structure, where calling <code>inc()</code> will modify a field within the counter. The other will be immutable -- calling <code>inc()</code> will return a new immutable counter containing the incremented value.</p>

<pre><code class="javascript">var counter = function() {
    var i = 0;
    return (function() {
        return {
            value: function() { return i; },
            inc: function() { i=i+1; return this; }
        };
    })();
}

var counterI = function() {
    var ctor = function(i) {
        return { 
            value: function() { return i; },
            inc: function() { return new ctor(i+1); } 
        };
    }
    return ctor(0);
}
</code></pre>

<h2>Equational reasoning</h2>

<p>In FP names are given to specific, immutable expressions. The idea is whenever we see a name, we can replace it with the expression it refers to without affecting the program's behaviour (this is known as <a href="http://en.wikipedia.org/wiki/Referential_transparency_(computer_science">referential transparency</a>)). We can use this fact to treat programs as mathematical equations -- if we see an <code>x</code> in an expression, we can replace it with whatever expression <code>x</code> equals.</p>

<pre><code class="javascript">var f = function (c) {
    return c.inc().value() - c.inc().value();
}
</code></pre>

<p>Let's reason through how <code>f</code> works when given an immutable <code>counterI</code>, by substituting in the meanings of each expression in the function.</p>

<pre><code class="javascript">// let c{i} = an immutable counter with a value i

f(c{i}) 
    = c{i}.inc().value() - c{i}.inc().value()
    = c{i+1}.value() - c{i+1}.value()           // by counterI.inc()
    = (i+1) - (i+1)                             // by counterI.value()
    = 0                                         // by (+), (-)
</code></pre>

<p>Here we've taken a fairly mechanical approach to evaluating this expression, but we can also apply mathematical/logical principles:</p>

<pre><code class="javascript">let x = c.inc().value()
in f(c)
    = x - x                 // by defn of x
    = 0                     // by (-)
</code></pre>

<p>And sure enough:</p>

<pre><code>&gt; f(new counterI().inc().inc())
0
</code></pre>

<p>So by substituting in values for names and vice versa, we can solve our equation to work out the program result, just as we would for any algebraic equation.</p>

<h2>Reasoning about evaluation and state</h2>

<p>We can't use the same equality of terms with mutable data, as the meaning of an expression can vary based on when it is called. One <code>c.inc().value()</code> expression does not necessarily equal another <code>c.inc().value()</code> expression.</p>

<pre><code>&gt; f(new counter().inc().inc())
-1
</code></pre>

<p>While mutability means we've lost referential transparency and equational reasoning, we can still reason about the code by keeping track of the state as we evaluate each expression. We'll treat this as a pair of values -- the evaluation on the left, and the state on the right.</p>

<pre><code class="javascript">(f(c), c: i)
    = (c.inc().value() - c.inc().value(), c: i)
    = (c.value() - c.inc().value(), c: i+1)         // by counter.inc()
    = (i+1 - c.inc().value(), c: i+1)               // by counter.value()
    = (i+1 - c.value(), c: i+2)                     // by counter.inc()
    = (i+1 - (i+1), c: i+2)                         // by counter.value()
    = (-1, c: i+2)                                  // by (+), (-)
</code></pre>

<p>So we can still reason about our code, we just have to keep track of the evaluation and the state separately. Not a big deal, and something we are very familiar with (and are probably quite adept at).</p>

<h2>The story so far</h2>

<p>We've found a few distinctions between reasoning about mutable and immutable code.</p>

<p>We managed to trace through our immutable example in 2 or 3 steps, while our mutable example took 5. This was because we replaced both occurrences of <code>c.inc()</code> at once in the immutable case, which we could do because the expressions are equal and referentially transparent. In the mutable case we had to do each step separately, as <code>c.inc().value()</code> does not necessarily mean the same thing as another <code>c.inc().value()</code>. So mutability is making reasoning more difficult for us by forcing us to evaluate more steps to understand our program.</p>

<p>Immutability also lets us apply algebraic laws and the properties of our code to gain an understanding about its result. We can use properties like <code>x - x = 0</code> for subtraction to help us understand the behaviour of our program, without ever needing to evaluate the <code>c.inc().value()</code> expression. So we can understand <code>f</code> without knowing anything about the counter instance other than its immutability.</p>

<p>In other words, immutability is enabling us to reason about our program independently from its execution. We can think logically about the code and only step through the parts we need. Mutability on the other hand inextricably links the meaning of the program with its method of execution, forcing us to go through the same execution steps at the computer will in order to understand it.</p>

<h2>Order in the court</h2>

<p>To further illustrate this coupling between program meaning and execution, let's try re-evaluating our mutable example in different orders.</p>

<pre><code class="javascript">// Left-hand side first (from above):
(f(c), c: i)
    = (-1, c: i+2)

// Right-hand side first:
(f(c), c: i)
    = (c.inc().value() - c.inc().value(), c: i)
    = (c.inc().value() - c.value(), c: i+1)        // RHS inc()
    = (c.inc().value() - (i+1), c: i+1)            // by value()
    = (c.value() - (i+1), c: i+2)                  // LHS inc()
    = (i+2 - (i+1), c: i+2)                        // by counter.value()
    = (1, c: i+2)                                  // by (+), (-)

// inc() calls, then value() calls:
(f(c), c: i)
    = (c.inc().value() - c.inc().value(), c: i)
    = (c.value() - c.value(), c: i+2)              // both inc() calls
    = ((i+2) - (i+2), c: i+1)                      // by value()
    = (0, c: i+2)                                  // by (+), (-)
</code></pre>

<p>Here we have three different results from three equally valid evaluations of the program. It is insufficient to understand what each piece of the program does, we also need to know exactly what way our target language and platform will execute it. The immutable version we can reason about independently of evaluation order.</p>

<p>We tend to work around this source of ordering confusion in the presence of mutability using imperative-style code. This makes ordering obvious (from top to bottom), and makes it easy for us to understand our program by stepping through it an instruction at a time:</p>

<pre><code class="javascript">function f(c) {                 // let c have initial state i
    c.inc();                    // c: i+1
    c.inc();                    // c: i+2
    var lhs = c.value();        // lhs: i+2
    var rhs = c.value();        // rhs: i+2
    return lhs - rhs;           // lhs - rhs = i+2-i-2 = 0
}
</code></pre>

<p>While this does make our program easy to understand, it still means we have to evaluate every line, and still doesn't make it apparent when we can use properties like <code>x-x=0</code> to help us understand the code.</p>

<h2>Aliasing</h2>

<p>What does this program return if <code>a</code> and <code>b</code> are mutable, and both have an initial counter state of <code>0</code>?</p>

<pre><code class="javascript">function g(a, b) {                  // let a: x, b: y
    a.inc();                        // a: x+1
    a.inc();                        // a: x+2
    b.inc();                        // b: y+1
    return a.value() - b.value();   // x+2-y-1 = x-y+1
}
</code></pre>

<p>We increment <code>a</code> twice and <code>b</code> once, then return the difference between the counters, so we should end up with <code>1</code>. Unless, of course, we get <code>0</code>:</p>

<pre><code class="javascript">var a = new counter();
var b = a;
g(a,b)
&gt; 0
</code></pre>

<p>Here <code>a</code> and <code>b</code> are <a href="http://en.wikipedia.org/wiki/Aliasing_(computing">aliased</a>) to the same instance^[Thanks to <a href="https://twitter.com/inkytonik">Tony Sloane</a> for pointing out some problems caused by aliasing to me. Please attribute mistakes in my interpretation to me because, unlike me, Tony knows what he's talking about. :)]. If <code>a</code> and <code>b</code> were different instances we'd get <code>1</code>. The problem is we can not correctly reason about what this code will do without knowing what <code>a</code> and <code>b</code> refer to.</p>

<p>In the immutable case, our output will always follow the formula we arrived at regardless of aliasing, as calls to <code>inc()</code> return new instances rather than mutating existing ones.</p>

<pre><code class="javascript">function g2(a, b) {
    return a.inc().inc().value() - b.inc().value(); // = x-y+1
}

var a = new counterI();
var b = a;
g2(a,b)
&gt; 1

var c = new counterI();
var d = new counterI();
g2(c,d)
&gt; 1
</code></pre>

<h2>Mutability in a larger context</h2>

<p>So far we have been dealing with code in a very limited scope. Within that scope we've seen that immutability lets us reason about a program independently of its execution, so we can understand it without having evaluate each term and can use algebraic substitution to simplify how we think about it.</p>

<p>In contrast mutability forces us to evaluate each step of a program to understand it, tracking of state in parallel with execution, requires call ordering to be specified explicitly, and also is subject to non-obvious behaviour due to potential aliasing of references.</p>

<p>Extrapolating to larger contexts, mutability means we now potentially need to evaluate every step of a program, keeping careful track of each piece of data's state for the duration of its scope, as well as tracking state updates via aliased references, in order understand what any single piece of the program is doing.</p>

<p>Due to a lack of side-effects, immutable code seems like it should always be understandable in isolation; its output depends purely on its input.</p>

<p>Based on this, it seems a clear-cut case of immutability leading to code that is easier to reason about, as promised by FP proponents.</p>

<h2>Mutability strikes back</h2>

<p>Perhaps mutability has other advantages that compensate for making it harder to reason about pieces of code in isolation.</p>

<p>One advantage is familiarity. Most of us learn programming in an imperative manner with mutable data, and this matches our intuition of how the von Neumann machine works^[See "Can Programming Be Liberated from von Neumann Style?" by John Backus for an excellent discussion of this topic. <a href="http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf">PDF link</a>]. I don't think it is fair to understate this point -- programming with pure functions and immutable data requires different approaches than those many of us have been applying for the entirety of our careers. My current feeling is that this knowledge is well worth pursuing for the benefits it brings.</p>

<p>There is also a question of time and space performance^[See <a href="http://blogs.msdn.com/b/bclteam/archive/2012/12/18/preview-of-immutable-collections-released-on-nuget.aspx">Preview of immutable collections released on NuGet</a>], or more specifically, reasoning about this performance. If our understanding of a program with immutable data is independent of its execution, then we need to reason about certain aspects of its performance separately again.^[A counter-argument to this that the prevalence of multi-core machines (even mobile phones have 4 as of 2012) makes reasoning about evaluation difficult even with mutable, imperative code. Linear reasoning is no longer reliable, especially if we want to take advantage of multiple threads.]</p>

<p>Another thing to consider is that programming by analogy may be easier to understand than logical reasoning. If we consider a counter as an analogy to an object we interact with in the physical world, then telling it to increase its value <a href="http://davesquared.net/2012/09/imperative-world.html">seems like a mutable operation</a>, with time and order of execution being an implicit part of the context we are in. If all our mutable objects behave in a way that keeps their state valid, and we control the order and scope of their mutations, then perhaps we can build systems that react reasonably as a whole. Although this does seem to imply we'd end up spending most of our time sorting out threading, scope and context, rather than expressing the solution to the problem unambiguously with immutable data and pure functions.</p>

<p>There are techniques to help us with keeping these mutations in check and for reasoning more logically about mutable code, such as <a href="http://en.wikipedia.org/wiki/Design_by_contract">design by contract</a> (DbC), which involves specifying pre- and post-conditions and invariants for mutable objects. If we can tell none of these conditions are violated by a program then we may be able to get some confidence that pieces work in isolation and that a system will work correctly as the sum of its parts.</p>

<p>As a side note, there may be other ways of getting benefits from message-passing analogies, while still maintaining the advantages of immutability and code we can reason about. Perhaps an approach like Erlang's, where we have components implemented in functional style communicating via message passing, gives us the best of both worlds.</p>

<h2>Conclusion</h2>

<p>When I first started experimenting with this topic I honestly imagined I would find more grey area between reasoning about mutable and immutable programs. Despite the simplistic example (and completely invalid sample size of the experiment ;)), I think we've identified some specific properties of immutable programs that make them easier to reason about than their mutable counterparts.</p>

<p>We can think about immutable programs independently from their execution, meaning we can understand them by evaluating less expressions, and in the context of various algebraic properties using equational reasoning. Mutable programs require us to track state at the same time as evaluating each step of the program, and are affected by ordering and aliasing ambiguities.</p>

<p>To leave myself a small paling of fence to sit on, it is worth noting that the last twenty-odd years of software development has been primarily taught in the context of mutable objects, and we have learned to reason about program execution and time and space use in this context.</p>

<p>Whether this gives rise to more intuitive behaviour in large systems compared to being able to apply sound logic to understand each part of a program is something I just don't know. My experiences programming using mutable objects have been less than stellar, which has led me to look much more closely at functional programming, but I just don't yet have enough experience with the latter in large projects to adequately judge the two.</p>

<p>Based on the properties outlined in this post, I definitely feel it is worth getting this experience. To me there is more than enough evidence to suggest a switch to immutable data is worth the potential risk and learning curve for the benefits of more understandable programs. If it turns out I'm wrong then I'm going to be very interested in identifying the characteristics of mutable data I have missed that do in fact make it easier to reason about.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[It's an imperative, mutable world out there]]></title>
    <link href="http://davesquared.net/2012/09/imperative-world.html"/>
    <updated>2012-09-11T10:05:00+10:00</updated>
    <id>http://davesquared.net/2012/09/imperative-world</id>
    <content type="html"><![CDATA[<p>I've heard Erik Meijer quoted as saying the world is imperative and mutable, and so we should embrace side-effects^[Erik Meijer from GOTO Night August 23, 2012 in Chicago: <a href="https://twitter.com/codemiller/status/238780672439885824">one</a>, <a href="https://twitter.com/codemiller/status/238783944043151360">two</a>, <a href="https://twitter.com/puffnfresh/status/238779939053252608">three</a>]. I've also heard what I interpret as pretty much the opposite from Rich Hickey^[<a href="http://www.infoq.com/presentations/Value-Values">Rich Hickey, GOTO 2012 Keynote: The Value of Values</a>]. So, which is it?</p>

<p>I'm not sure, but maybe a story about dinosaurs will help.</p>

<h2>Somehow we all escaped with our lives</h2>

<p>It was a brisk winter's night. I had just parked my car down at The Rocks, a beautiful part of Sydney right on the Harbour, and had started hurrying down George Street to attend the monthly Drop Bear Awareness Society meetup. I had only gone a couple of hundred metres when hordes of people started flooding out of Circular Quay directly across the road from me, accompanied by yells, screams and sirens. I was swept along with the crowd, herded by police and emergency services into Town Hall station and onto waiting trains. As my train pulled away from the platform I only knew one thing for certain; people were talking about a "monster" with a disturbing amount of credulity.</p>

<p>Turns out that a 50 metre high dinosaur-like monster had chosen that day to emerge from the depths of Sydney Harbour and take a brief stroll through the CBD. It was apparently on land for about 10 minutes, after which time it had grown bored and decided go head to Melbourne where it could destroy something more tasteful.</p>

<p>I returned to my car the next day. It was flattened; the imprint of a giant footprint clearly visible in the twisted wreckage. But I wasn't going to give up on my beloved car. It took weeks of extensive work at the smash repairer, but I finally got my car back, pretty much as good as new.</p>

<h2>State, mutations and time</h2>

<p>There are two ways of looking at this story (three if you count "as an unimaginative, poorly-told piece of tripe"). One is from the perspective of mutable state, as commonly associated with imperative programming^[Imperative programs are just sequences of instructions and can also be done without mutable state, although <a href="http://en.wikipedia.org/wiki/Imperative_programming">some definitions</a> include mutability as an essential feature.]. I had a working car, then the car's state changed to "smashed by monstrous dinosaur", then it changed back to working. It was the same car, its state was just changed, and rather forcibly at that. We can even write a program to express what happened:</p>

<pre><code class="csharp">var car = new Car("British Leyland Mini 1000");
Console.WriteLine(car.State); // prints "Working"
car.SmashWith(new DinosaurThing()); 
Console.WriteLine(car.State); // prints "Smashed"
car.Repair();
Console.WriteLine(car.State); // prints "Working"
</code></pre>

<p>The <code>SmashWith</code> and <code>Repair</code> methods have side-effects; they mutate the <code>State</code> property of the car as the program executes. One interesting result of this is that the <code>State</code> property is always tied to the concept of "now"; its value is inextricably linked to the point in time at which it is called. We have several states in this program, but whenever we talk about state, we are only referring to the current state.</p>

<p>I tend to think of the concept of time being an <em>implied</em> part of this representation. Any state change requires a change in time, but this representation never refers to time explicitly. The time is always "now", and evaluating the next statement is always done in that context. From the perspective of "now", this representation is completely valid.</p>

<p>For programming in particular though, this perspective is not without its problems. Because time is implicit in this representation, "now" changes from instruction to instruction, and so it is possible for operations to interfere. Any contention for the state between operations, such as concurrent access (multi-threading) or temporal coupling (<code>Repair</code> only makes sense when the car is smashed after a call to <code>SmashWith</code>) can result in an inconsistent state. To reason about a program, we also have to mentally evaluate it by stepping through all the instances of "now" that can occur.</p>

<p>There is another, equally valid way of thinking about this story. In this telling we make the time variable explicit. The state of the car is a function of time:</p>

<pre><code class="csharp">public static CarState GetCarState(Time t) {
    const CarState InitialState = CarState.Working;
    const CarState SmashedByDinosaur = CarState.Smashed;
    const CarState RepairedState = CarState.Working;
    if (t &lt; 0) 
        return InitialState;
    else if (t &gt;= 0 &amp;&amp; t &lt; 10) 
        return SmashedByDinosaur;
    else 
        return RepairedState;
}
</code></pre>

<p>Here we still have state changes, but they aren't destructive. Just because my car is now fixed does not mean that is was never smashed by a giant, 50 metre high mostrosaur. That state was still perfectly valid, it was just at a different time. Because time is an explicit input it is not possible to get interfering states. The output depends purely on the input, and is defined for all values of <code>t</code>.</p>

<p>One effect of treating state as a function of time is that data necessarily becomes immutable. Once we have data for some time <code>t</code>, that data is never going to change; we can't change the past. A change in state over time will result in a new piece of data.</p>

<pre><code class="csharp">public static Car GetCar(Time t) {
    // Works nicer in a lazy / non-strict language... :)
    var car = new Car("British Leyland Mini 1000");
    var smashedCar = car.SmashWith(new DinosaurThing());
    var repairedCar = smashedCar.Repair();
    if (time &lt; 0) return car;
    else if (time &gt;= 0 &amp;&amp; t &lt; 10) return smashedCar;
    else return repairedCar;
}
</code></pre>

<p>And just because we can explicitly handle time does not mean we have to expose it. Immutable data is enough to ensure we don't interfere with previous states:</p>

<pre><code class="csharp">var car = new Car("British Leyland Mini 1000");
var smashedCar = car.SmashWith(new DinosaurThing());
var repairedCar = smashedCar.Repair();
</code></pre>

<p>One thing that may seem troubling is we now have different instances of data representing the one car, but we can associate these using identity (the car's VIN, make, model, etc.) rather than by reference as per the mutable-imperative approach. The state of a car with a specific identity can be considered a function of time and identity with an immutable data representation as the output. Again, all these states are valid, they actually occurred in the story, and we just need to be explicit on which moment of reality we need to work with.</p>

<h2>Imperative world?</h2>

<p>So the world is imperative, full of mutations and side-effects. But it seems equally valid to say that the world is a function of time (and other variables) that outputs immutable states. Perhaps both perspectives are two sides of the same coin, just separated by their treatment of time.</p>

<p>To me the potential equivalence of these perspectives matches my admittedly-basic-and-quite-probably-wrong interpretation of the <a href="http://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis">Church-Turing thesis</a>: all computable programs are computable by both a Turing machine and using the λ-calculus. A Turing machine relies on mutable state, λ-calculus on pure functions. They're all able to express the same set of programs, and they can all represent "real world" information and calculations.</p>

<p>The question for programmers is which perspective on state makes programs easier to reason about and work with. And if the answer varies from problem to problem, what particular aspects of a problem make it well-suited to that perspective?</p>

<h2>Intuition</h2>

<p>One thing to consider before you answer is how much of our opinion is swayed by what John Backus referred to as "the primacy of the von Neumann computer"^["Can Programming Be Liberated from the von Neumann Style? A Functional Style and Its Algebra of Programs", John Backus, Communications of the ACM August 1978. <a href="http://www.cs.cmu.edu/~crary/819-f09/Backus78.pdf">PDF link</a>].</p>

<p>Most of us have been trained from our very first experience with a computer (Assembler? C? C64 Basic? Java?) until now to think about programs in terms of the von Neumann architecture, where we process an instruction at a time and store to and load from mutable registers. In evaluating these perspectives we need to overcome decades of language and architecture bias. Both perspectives are equally valid when talking about the world around us, both can express the entire set of computable programs, and yet most platforms and languages emphasise mutability.</p>

<p>So it seems reasonable to be a little suspect of both our intuition and of the status quo in this case. Intuitively we understand that things change their state, but logically we also recognise that state depends on time, and a new state at a particular time does not destroy the state at the previous time.</p>

<h2>Conclusion</h2>

<p>In summary, don't park right next to a large, city-side harbour unless you have comprehensive car insurance.</p>

<p>And let's challenge ourselves about the idea that mutability is somehow essential to programming and to expressing concepts from the "real world".</p>

<p>But mainly the parking thing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Design via minimum code]]></title>
    <link href="http://davesquared.net/2012/05/design-via-minimum-code.html"/>
    <updated>2012-05-01T22:10:00+10:00</updated>
    <id>http://davesquared.net/2012/05/design-via-minimum-code</id>
    <content type="html"><![CDATA[<p>Being a bit of a <a href="http://en.wikipedia.org/wiki/Pessimism">realist</a> (;)), I find it much easier to find problems with my design ideas than I do finding designs I'm really happy with. I am always cognisant of this and make sure to balance the needs of doing a good job and getting the job done. One technique I find useful for this is thinking about the minimum amount of code required.</p>

<p>Whenever I find myself evaluating different design patterns or counting responsibilities to work out where the feature should go or which areas I should refactor, I stop and work out the minimum amount of code I'd need to write to solve the problem, ignoring design considerations. Once I've starting thinking about the problem in that light, working out where to put that code becomes a bit easier. If the code violates my sense of design aesthetics, it could just be because it is a messy problem, and no matter how hard I try to abstract or design my way out, the fundamental messiness still remains.</p>

<!-- more -->


<p>As an example, say we're working with a library that misuses exceptions, throwing for genuine exceptional cases, and also as a way to notify callers of a change in mode. I might find myself getting grand ideas like anti-corruption layers, Command patterns with reused error handling, or trying various continuation ideas. If there's a lot of existing code I might start getting bogged down in working out all the classes I'm going to have to change to fit in with this new error handling infrastructure. These kind of premature generalisations are a sure sign I need to stop and simplify.</p>

<p>If we think about the problem for the moment, at a minimum we're going to need a <code>try .. catch</code> somewhere, and chances are we're going to have to do something disgusting like swallow the irrelevant exceptions. We're now in a position to think about exactly where this responsibility should go based on our standard design rules. In this case, it may be best to deal with this immediately at the boundary between our code and the library, rather than creating a more formal abstraction for handling them (or not, the point is that we know the code and minimum mess required, so we are in a better position to work out where to put it).</p>

<div class="note">**Note:** I'd like to be sure to quickly distinguish this from [YAGNI](http://en.wikipedia.org/wiki/YAGNI), which in my experience is a decent idea frequently misused for copping out. Once we've determined the minimum amount of code required, if doing a bit of work to get that into a nice shape is needed then calling faux-YAGNI is definitely inadvisable.</div>


<p>TDD can be a useful way to do a similar thing; writing a test that uncovers the minimum increment of code required. Sometimes though it's not clear from what class or in which direction you should drive the code, in which case I've found thinking in terms of the minimum amount of code required then spiking some options around that a helpful alternative.</p>

<p>So next time you're pondering whether to toggle a UI element's visibility using MVVM or an MVP-variant for UI separation, or whether to push the conditional in to a Strategy implementation, just remember that somewhere along the line an evil <code>if</code> statement or similar is going to have to execute and switch the element's visibility switched from "visible" to "hidden".</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some mocking opinions]]></title>
    <link href="http://davesquared.net/2011/11/some-mocking-opinions.html"/>
    <updated>2011-11-22T22:25:00+11:00</updated>
    <id>http://davesquared.net/2011/11/some-mocking-opinions</id>
    <content type="html"><![CDATA[<p>I've been thinking through how I use test doubles (mocks, stubs, test spies, etc) recently, and thought I'd write down a snapshot of my current opinions on the subject.</p>




<h2>Don't mock types you don't own</h2>




<p>I've <a href="http://davesquared.net/2011/04/dont-mock-types-you-dont-own.html">written about this before</a>, and I still think it is good advice. Test down to your lowest level of abstraction, then integration / contract / acceptance test over the boundary. By mocking a type you don't own that dependency starts bleeding in to your code and pushing your own abstractions in potentially unhelpful ways. You're also not really testing much; unless you also have good contract tests then checking you've called a specific external method is not going to tell you much about whether your code does what it needs to.</p>




<p>Contrived example: say I was faking out <code>Math.Round()</code> (let's pretend it's an instance method or you are using a framework that can mock statics via the profiler API):</p>




<pre><code>[Test]
public void Calculate_with_rounding() {
    math.Round(2.5).Returns(3); //Fake math.Round
    var subject = new Calculation(math);

    Assert.AreEqual(subject.AddAndRound(1, 1.5), 3);
}
</code></pre>




<p>Perfectly reasonable? Well, except for the fact .NET uses banker's rounding and rounds <a href="http://stackoverflow.com/questions/977796/in-c-math-round2-5-result-is-2-instead-of-3-are-you-kidding-me">2.5 to 2</a> (and 1.5 to 2 for that matter). If you were using Python (which rounds away from 0), you would have been spot on. If you care about the rounding method, you've now got a bug.</p>




<p>If something as simple as rounding can trip us up, imagine what we could do if we start mocking ORM or ADO.NET calls.</p>




<h2>Try to avoid mocks in acceptance tests</h2>




<p>In my experience this tends to result in too much behaviour being pushed into the mocks. My first preference is to use real pieces, second is to hand-code fakes that have enough logic to work as required, and convenience methods to help tests configure them appropriately. As per &quot;don't mock types you don't own&quot;, it is also a good idea to test your fakes match the real behaviour.</p>




<h2>Learn mocking before a mocking framework</h2>




<p>I've often heard developers new to automated testing say things like &quot;I really need to learn (Rhino Mocks | Moq | Mocking Framework X)&quot;. I think this is the wrong emphasis; before learning a framework for creating test doubles it's important to understand how test doubles work and how to use them.</p>




<p>For me, a great way to learn was to hand-roll all my fake objects for my tests to act as required. Manually stubbing out values and/or recording calls gave me a good understanding of the different types of test doubles (mocks, spies, stubs etc.) and how they work. Once this got old (very quickly) it was fairly simple to take the behaviour I knew how to hand-code and translate that into the syntax required by a mocking framework. It just became a matter of automating what I was already doing. (It also helped me understand common difficulties like trying to mock non-virtual members.)</p>




<h2>Don't explictly test intermediate steps or inconsequential details</h2>




<p>If we assert on details of an implementation we tend to get tight coupling and brittle tests. An example I have seen fairly frequently is:</p>




<pre><code>[Test]
public void Should_get_the_widget_from_the_factory() {
    var factory = MockRepository.GenerateMock&lt;IWidgetFactory&gt;();
    var subject = new Foo(factory);
    subject.DoStuff();
    factory.AssertWasCalled(x =&gt; x.GetWidget());
}

[Test]
public void Should_turn_the_widget() {
    var widget = MockRepository.GenerateMock&lt;IWidget&gt;();
    var factory = MockRepository.GenerateStub&lt;IWidgetFactory&gt;();
    factory.Stub(x =&gt; x.GetWidget()).Return(widget);
    var subject = new Foo(factory);
    subject.DoStuff();
    widget.AssertWasCalled(x =&gt; x.Turn());
}
</code></pre>




<p>Here the first test is a completely redundant. The second test covers that entire code path (how else could the widget from the factory get turned, if the subject did not call the factory?). Now you could argue that you prefer the extra, explicit specification the first test provides, to which I'd respond that I don't think it's worth the pain from the additional friction it causes when you want to change this implementation detail. </p>




<p>Besides, what do we really care about for our subject? That it uses a factory? Or that it turns the widget? Focus on how you want the object to behave, not how it implements that behaviour.</p>




<p>This approach can help lead us to better abstractions, as we start identifying roles and responsibilities separately from implementation details. And it will definitely make your code easier to change without the friction of over-specified tests.</p>




<h2>Mock interaction with the contract, not the specific implementation</h2>




<p>On a highly related point, the aim of abstraction is decoupling from the implementation. If we are configuring our test doubles with lots of behaviour that our unit tests are relying on then our object is coupled to that particular implementation, not to a contract of behaviour or a role. For an abstraction to be effective we should be able to drop in a completely new implementation that fulfils the required role. This is not the case if we need to set up a test double's method to call another dependency and return some rearrangement of the result. If we're relying on that in our test then our abstraction has failed.</p>




<p>Sometimes you just get stuck with having to perform a callback from a stub, but in general if you are pushing behaviour into your mock, re-think the design or consider using a hand-coded fake before you go contorting your mocking framework.</p>




<h2>Beware over-abstraction</h2>




<p>It is quite easy to churn out layers of useless abstractions when using mock frameworks. Abstractions have a cost. Feedback from tests is great, but pay close attention to SOLID and the rules of simple design and call out to meaningful abstractions, rather than putting in a dependency just for testing. I wrote some <a href="http://davesquared.net/2011/06/abstraction-and-oo.html">guidelines on abstractions</a> a while back that I don't entirely disagree with yet.</p>




<h2>Some unanswered questions</h2>




<h3>Mocks vs. stubs, tell vs. ask.</h3>




<p>I've tended to prefer stubs over mocks (stubbing out the results of calls rather than checking they were received), as per the widget factory example above. This flies in the face of the &quot;Tell, don't ask&quot; principle, which recommends we don't ask a collaborator for some state and act on the result, but instead give the collaborator the state it needs from us and tell it what to do with it. This seems to suggest I should be using mocks (checking received calls) a whole lot more than I stub them out.</p>




<h3>Avoiding &quot;Yet Another Factory&quot;</h3>




<p>If an object news up something, our unit test will typically have almost no ability to affect that object. If we want to check our subject news up a view model and calls <code>Activate()</code> on it, we have no way of asserting this was done without exposing <code>IsActivated</code> and relying on that implementation detail. Leaky abstraction. Bad.</p>




<p>One solution is injecting a factory into our object. We can stub out what this returns, make it return another test double, and then check it received the <code>Activate()</code> call. Just introduce a factory. Yet another factory. Searching through files matching <code>*Factory</code> becomes an exercise akin to reading War and Peace. And they're generally not even <a href="http://en.wikipedia.org/wiki/Factory_pattern">real factories</a>! They don't choose a particular implementation, they are just a glorified wrapper over a single constructor.</p>




<p>Sure, I sometimes try to ease my conscience by injecting a factory method as a <code>Func&lt;T&gt;</code> which my IoC container helps me with. But deep down I know it's still YAF, and a small part of me dies.</p>




<p>I'm hoping choosing &quot;better&quot; abstractions will help me with this, but I've had limited success to date.</p>




<h3>Interface explosion</h3>




<p>C# seems to make it difficult to do testing without using interfaces. And so I end up pulling out yet another interface that will never see another implementation. I've heard <a href="https://twitter.com/shannoncornish">Shannon</a> refer to them as &quot;the new header files&quot;. Every class has its interface documented in its header/interface file. It's easy to say just choose better abstractions where the interface can be reused, but this is still something I struggle with.</p>




<h3>Mocking in dynamic languages</h3>




<p>This post has been written primarily from the perspective of static languages; I not sure how much (if any) applies to dynamic languages. From my limited experience testing and mocking seem to be done quite differently in languages like Ruby and Python. I'm keen to learn more about how mocking is done in these languages and see how much can help me improve how I test.</p>




<h2>End of transmission</h2>




<p>This has been a brain dump of my current opinions about mocking. If you agree, disagree, and/or can help me with some of my unanswered questions, please leave a comment.</p>




<p>Now if you'll excuse me, I'm off to code up yet another factory...</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unhelpful flaming is unhelpful]]></title>
    <link href="http://davesquared.net/2011/09/unhelpful-flaming-is-unhelpful.html"/>
    <updated>2011-09-20T23:47:00+10:00</updated>
    <id>http://davesquared.net/2011/09/unhelpful-flaming-is-unhelpful</id>
    <content type="html"><![CDATA[<p>I recently read an excellent post on <a href="http://ecomwriter.com/2011/09/08/patience-and-respect/">patience and respect</a> from Andrew Sharp, suggesting the radical idea of trying to empathise with the much-maligned <i>whoever-wrote-this-steaming-pile-of-code-that-I-now-have-the-misfortune-of-having-to-work-with</i> instead of the usual cursing of the previous author's name, professionalism, family, and very existence in a bout of barely contained nerd-rage.</p>




<p>This is often quite embarrassing when you realise the previous author was you, but this isn't the only reason to stop the practice of flaming the authors of rotten code.</p>




<p>Yes, this post is basically a rehash of <a href="http://ecomwriter.com/2011/09/08/patience-and-respect/">Andrew's post</a>, but as it resonated with me I felt compelled to write down my perspective on the topic. His is concise and beautifully written, but mine briefly teases SharePoint, so take your pick. :D</p>




<h2>The situation</h2>




<p>You open the code. It's worse than you thought. Your face falls as you flick through the files you need to change, and see one or more of the following:</p>




<ul>
<li>Classes with thousands of lines.</li>
<li>Methods with thousands of lines.</li>
<li>Nested <code>if</code>s so deep you need to scroll horizontally to find the end of the arrow.</li>
<li>Constructors with 17 arguments.</li>
<li><a href="http://www.richard-banks.org/2011/02/anti-region-campaign.html">Regions</a>.</li>
<li>No trace of automated testing. Or of even having been manually tested.</li>
<li>Code that only works due to some obscure side-effects.</li>
<li>Code that only works on Tuesdays.</li>
<li>Liberal sprinklings of <code>Thread.Sleep</code>.</li>
<li>Object Oriented code where all object members are static.</li>
<li>No.respect_for.the_law().of.demeter()</li>
<li>SharePoint involved somewhere.</li>
<li>Incredibly clever code featuring an abstract factory pattern to produce strategies which are injected into commands applied with double dispatch using the visitor pattern, proxying through to WCF calls batched into units of work and persisted using an EF entity data model. You can't help but think this is overkill to print FizzBuzz.</li>
</ul>




<h2>The initial reaction</h2>




<ul>
<li>WTF!?!?</li>
<li>No seriously; WTF?!!?!?</li>
<li>What were they thinking?</li>
<li>What an unprofessional jerk!</li>
<li>How do they sleep at night?!?!</li>
<li>I've got to post this to twitter. Everyone will get a good laugh at this.</li>
<li>Oh, and I'll blog it! There's another couple of hundred people to pour scorn and ridicule on this deserving schmuck!</li>
<li>Even better, I'm posting this to thedailywtf.com!</li>
</ul>




<div class="separator" style="clear: both; text-align: center;">
<a href="http://www.osnews.com/story/19266/WTFs_m" imageanchor="1"><img border="0" height="377" width="400" src="http://davesquared.net/images/fromblogger/s400-wtfm.jpg" /></a></div>




<h2>Stop! Hammertime!</h2>




<p>What exactly are we doing here? We're all puffed up with self-righteous indignation, but what is this vehement response going to accomplish? Shame an incompetent person out of programming, thereby ridding the glorious profession of software development of one of those rare dullards that somehow slip into the ranks of the brilliant, intellectual master-craftsmen and women that dominate the industry? (In case it isn't clear, that sentence carries a &lt;sarcasm/&gt; tag :P).</p>




<p>Probably not. All we're doing is stroking our own egos, delighting in someone else screwing up for a change, and further fostering the culture of competitiveness, elitism and macho-attitudes that seem to keep <a href="http://www.jamesthigpen.com/blog/2009/02/28/altnet-seattle-2009-why-so-mean/">popping up in our industry</a>.</p>




<p>Sure, short-term you may feel better for venting, but adding to the bile on the internet is a bit like peeing in the dam that supplies your own drinking water.</p>




<p>So what could we do instead?</p>




<h2>Consider the context</h2>




<p>Let's take a deep breath, then start thinking about why this code stinks. It is important to realise that people are generally trying to do good work. There are probably valid reasons the code you are currently staring at seems wrong, and most of them probably have nothing to do with trying to spite you.</p>




<ul>
<li>The author is inexperienced.</li>
<li>The author does not have experience with that particular problem.</li>
<li>The author is trying a new approach in an attempt to learn.</li>
<li>The author doesn't know about a language feature, pattern, or project convention.</li>
<li>The author was working to an insane deadline that would cost the company millions if the feature wasn't out the door in 33 minutes.</li>
<li>The author was actually confronted with worse code, and did substantial tidy up of a whole bunch of classes and extracted the most ugly bit to a place where it could be refactored later (i.e. where you currently need to modify ;)). The reason you are not currently fighting another 3 fires is because of the work they did.</li>
<li>The author knew the code wasn't perfect, but it wasn't obvious at the time how else to factor it.</li>
<li>The author just seperated from their long term partner, they have a parent in hospital, their car was smashed by an uninsured driver, their bank just increase its mortgage rate and their pet just died in a tragic canoeing accident. They had trouble concentrating on the code they wrote that week.</li>
<li>The author implemented a bunch of awesome classes, and this one.</li>
<li>The author wrote the code in a way that was perfect at the time, it's just that times have changed.</li>
<li>The code is actually really good. We just don't see the beauty of it.</li>
<li>The author made a mistake. You may remember making one or two of these yourself in your younger days.</li>
<li>The author was forced at gunpoint to write the code by a rogue PM who was also holding the author's family hostage, dangling them precariously over a vat of potent hydrochloric acid while screaming "add another responsibility to the class or they all get it! Add more regions and superfluous comments! And CLOSE THAT CLASS FOR EXTENSION!!! DO IT!!!1!"</li>
</ul>




<p>None of this means the author is a bad person, and yet us programmers seem to take perverse delight in opening some code and sniggering "WTF?!!? What were they thinking?" while firing up our favourite blame tool. Maybe it just makes us feel better about all the cruddy code we've written?</p>




<h2>Opportunities</h2>




<p>Instead of dwelling on the negatives, let's look at the opportunities the code has given us to do some more constructive things than suggested by our initial reactions.</p>




<ul>
<li>If this is public code, we could contact the author, thank them for being brave enough to share the code in the first place, and <a href="http://ecomwriter.com/2011/09/08/patience-and-respect/">constructively suggest alternate approaches</a>, explaining the rationale for doing so and being careful to keep the person and the code separate (e.g. favour "this class could use a factory to create this instance" or "we could use a factory..." over "you shouldn't create this here, use a factory". This helps get past people's natural tendency to become defensive, and prevents you from slipping into flame mode.)</li>
<li>If you work with the person, maybe consider how <a href="http://davesquared.net/2010/08/there-is-no-u-in-collective-ownership.html">collective ownership</a> applies, and think about how the team can improve things in future.</li>
<li>If you can see how the code ended up in its present state and what to do about it, take the general concepts (not the personal attack) and blog that, post it to a programming mailing list, conduct a brownbag session at work, present the general principles at your local usergroup, talk at a conference, get on a podcast, start a podcast. Teach it. Educate. Play a small but valuable part in lifting the community and advancing the practice of programming.</li>
<li>Think about how APIs or patterns could change or be used to prevent the problem. Release an open source project that makes getting it right easy and obvious (as well as an explanation of why this approach works).</li>
<li>Practice giving criticism in a constructive, respectful way. This is a skill worth developing.</li>
<li>Recognise that <a href="http://davesquared.net/2011/08/technical-debt.html">there is no perfect, tech debt-free solution</a>, and think up of lots of ways to fix the problems you see in the code. This will help you to improve both your coding and your perspective. Combine this with aforementioned blogging, presenting, teaching etc.</li>
<li>Encourage the author. Programming is hard; praising anything good about the code and encouraging them to try improvements can give them more confidence to tackle future problems more creatively. It's amazing what being freed from the fear of failure can do.</li>
<li>We could, hmm, I dunno, maybe FIX THE DARN CODE AND MOVE ON WITH OUR LIVES!!! ;)</li>
</ul>




<div class="note"><b>Tip:</b> While explaining a techinical concept, avoid condescending words or words that diminish the task like "simply", "basic", "trivial", and "obvious". It may be to you, or it may be in hindsight. Recognise that if it were any of these things to the author, then they would have done it that way in the first place.</div>




<h2>Why bother?</h2>




<p>Because programming culture seems filled with large egos, worthless competitiveness, negativity, and cults around celebrities which discourage both creative thinking and challenges to the status quo. And yet we also have many examples of selflessness and generosity: people pouring hundreds of hours into OSS projects, donating their time to usergroups and mailing lists, and blogging stuff they learn so that others may benefit. Let's spend more time on these positives within the dev community. By focusing on the opportunities finding "bad" code gives us, I believe we can get a community where:</p>




<ul>
<li>People can ask honest questions without being told to "RTFM n00b".</li>
<li>People spend more time discussing different approaches than defending previous ones.</li>
<li>People can post sample code or OSS projects without being ripped apart and mocked, but instead given constructive advice and congratulations for having the guts to risk failing in public.</li>
<li>All people can contribute; not just the loudest, most extroverted, most confident personalities. A more diverse group of people will provide more diverse ideas and innovations.</li>
<li>Failure starts to be considered a wonderful thing, as even a single failure is an opportunity for many people to learn and improve as developers.</li>
</ul>




<p>Please leave your flames and ad hominem attacks in the comments. ;)</p>



]]></content>
  </entry>
  
</feed>
